{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41ea6447",
   "metadata": {},
   "source": [
    "# U-ViT CIFAR-10 Baseline Training\n",
    "\n",
    "This notebook implements the simple baseline for the `baofff/U-ViT` diffusion model repository, using the **CIFAR-10** dataset (Pixel-Space Diffusion with U-ViT-S/2 model).\n",
    "\n",
    "**⚠️ IMPORTANT:** Ensure your Colab runtime type is set to **GPU** (Runtime -> Change runtime type)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66f79a2",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependency Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064950bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability (must show a T4, V100, or equivalent)\n",
    "!nvidia-smi\n",
    "\n",
    "# Clone the repository and change directory\n",
    "!git clone https://github.com/chenchenhou/Adaptive-Patch-DiT.git\n",
    "%cd U-ViT\n",
    "\n",
    "# Install core Python dependencies\n",
    "print(\"\\n--- Installing Core Dependencies ---\")\n",
    "!pip install accelerate==0.12.0 absl-py ml_collections einops wandb ftfy==6.1.1 transformers==4.23.1\n",
    "\n",
    "# Install xformers for performance optimization\n",
    "print(\"\\n--- Installing xformers for Optimization ---\")\n",
    "!pip install -U xformers\n",
    "!pip install -U --pre triton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cda1fcd",
   "metadata": {},
   "source": [
    "## 2. Configure Hugging Face `accelerate`\n",
    "\n",
    "We create a non-interactive configuration file (`default_config.yaml`) for `accelerate launch`, setting it up for a **single GPU** (typical Colab environment) with **mixed precision (`fp16`)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5473cc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile default_config.yaml\n",
    "# Configuration file for accelerate (for single GPU Colab environment)\n",
    "compute_environment: LOCAL_MACHINE\n",
    "distributed_type: NO\n",
    "downcast_gb: null\n",
    "gpu_ids: '0'\n",
    "machine_rank: 0\n",
    "main_training_function: main\n",
    "mixed_precision: fp16\n",
    "num_machines: 1\n",
    "num_processes: 1\n",
    "rdzv_backend: static\n",
    "same_network: true\n",
    "tpu_core_index: 0\n",
    "tpu_zone: null\n",
    "use_cpu: false\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9536f122",
   "metadata": {},
   "source": [
    "## 3. Run the CIFAR-10 Baseline Training\n",
    "\n",
    "This cell executes the training script (`train.py`) using the `cifar10_uvit_small.py` configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffcef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SCRIPT=\"train.py\"\n",
    "CONFIG_FILE=\"configs/cifar10_uvit_small.py\"\n",
    "ACCELERATE_CONFIG=\"default_config.yaml\"\n",
    "\n",
    "print(\"Starting CIFAR-10 U-ViT Baseline Training...\\n\")\n",
    "\n",
    "# The CIFAR-10 dataset will be automatically downloaded.\n",
    "# Training may take a long time (500k iterations for paper results).\n",
    "\n",
    "!accelerate launch \\\n",
    "    --config_file {ACCELERATE_CONFIG} \\\n",
    "    {TRAIN_SCRIPT} \\\n",
    "    --config={CONFIG_FILE}\n",
    "    \n",
    "print(\"\\nTraining process initiated. Check the output for logging and checkpoint paths.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
